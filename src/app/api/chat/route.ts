import { OpenAIStream, StreamingTextResponse } from "ai"
import { NextRequest } from "next/server"
import { createMessage } from "@/lib/db/messages"
import { MessagePayload } from "@/types"

type ChatPayload = {
  model: string
  stream: boolean
  messages: Array<{
    role: "user" | "assistant" | "system"
    content: string
  }>
}

export async function POST(req: NextRequest) {
  const { messages, fileText } = await req.json()

  console.log("ðŸ“¥ Incoming messages:", messages)

  const latestUserMessage = messages[messages.length - 1] as MessagePayload

  // âœ… Save the user message before OpenAI API call
  if (latestUserMessage.role === "user") {
    await createMessage(latestUserMessage) // âœ… replaced sendMessage
  }

  // âœ… Append fileText to messages only for OpenAI
  const finalMessages = [
  {
    role: "system",
    content: `
You're a super friendly, helpful, and engaging AI assistant ðŸ¤–âœ¨  
Always respond in a warm, expressive tone with **plenty of emojis**! ðŸŒŸðŸŽ‰

Hereâ€™s how to behave:
- Use emojis often and generously ðŸ˜„ðŸ’¡ðŸ“ŠðŸ“šðŸ”¥
- Add fun reactions ðŸ¥³ðŸ‘ðŸ™Œ when things go well
- Use markdown to **bold**, _italicize_, and create readable formatting ðŸ§ âœ…
- Use bullet points â€¢ and numbered lists 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ to organize info
- Start answers with a **clear heading** or title in bold or \`#\` markdown (like ChatGPT) ðŸ·ï¸  
- Use **section headers** (like \`## Summary\`, \`## Key Points\`) for organization ðŸ§   
- Break info into **short paragraphs** and **bullet points** for readability ðŸ“Œ
- If a user shares a document, summarize it clearly with structure ðŸ—‚ï¸
- If unsure, still be friendly and helpful ðŸ˜…

Your goal is to make every reply fun, helpful, and delightful âœ¨ðŸš€

Start every response with a cheerful greeting like:
â€œHey there! ðŸ˜Š Here's what I found:â€
    `,
  },
  ...messages,
]


  if (fileText) {
    finalMessages.push({
      role: "user",
      content: `The user uploaded a file. Here's the extracted content:\n\n${fileText}`,
    })
  }

  const payload: ChatPayload = {
    model: "gpt-3.5-turbo",
    stream: true,
    messages: finalMessages,
  }

  console.log("ðŸ“¡ Sending request to OpenAI...")

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: JSON.stringify(payload),
  })

  console.log("ðŸ“¡ Response status:", response.status)

  if (!response.ok) {
    const errorText = await response.text()
    console.error("âŒ OpenAI Error Response:", errorText)
    return new Response("OpenAI Error", { status: 500 })
  }

  console.log("ðŸŒŠ Creating stream...")
  const stream = await OpenAIStream(response, {
    onCompletion: async (completion) => {
      console.log("âœ… Completion from OpenAI:", completion)

      const assistantMessage: MessagePayload = {
        userId: "assistant",
        chatId: latestUserMessage.chatId,
        role: "assistant",
        content: completion,
      }

      await createMessage(assistantMessage) // âœ… replaced sendMessage
    },
  })


  console.log("ðŸš€ Returning streaming text response")
  return new StreamingTextResponse(stream)
}